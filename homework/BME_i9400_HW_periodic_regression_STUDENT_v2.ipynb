{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb3dbc64",
      "metadata": {},
      "source": [
        "## BME i9400\n",
        "## Fall 2025\n",
        "\n",
        "### Homework 1: Learning Periodic Structure Beyond Polynomials\n",
        "\n",
        "**Assigned:** 2025-10-06  \n",
        "**Due:** 2025-10-20 11:59:59.999 PM EST\n",
        "\n",
        "**Place completed notebook into your \"my-work\" folder on JupyterHub**\n",
        "\n",
        "**Learning goals**\n",
        "- Understand **why** polynomial regression fails on multi‑cycle periodic data.\n",
        "- Implement **your own cross‑validation loop** using provided k‑fold indices.\n",
        "- Build sinusoidal/Fourier feature bases and use **ridge regression** with CV.\n",
        "\n",
        "**Honor & AI use policy (read carefully)**\n",
        "- You may use docs/StackOverflow for syntax.  \n",
        "- You **may** ask an LLM for debugging/snippets, but you must include an **AI Log** at the end (prompts + what you used).\n",
        "- You **may not** ask for a full solution. Your code and plots must reflect your own understanding.\n",
        "\n",
        "**Deliverables**\n",
        "1. Executed notebook (.ipynb) with all cells run. \n",
        "2. `ai_log.md` (if you used an LLM)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d0183ba",
      "metadata": {},
      "source": [
        "**What YOU write (student-supplied code):**\n",
        "- `poly_features`\n",
        "- The **cross‑validation loop** for polynomials (store per‑degree train/val MSEs)\n",
        "- `fourier_features` (no trend; bias optional)\n",
        "- Parts of `cv_ridge` (append fold MSEs; record means; choose best α)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea3f3ce8",
      "metadata": {},
      "source": [
        "**Provided (do not change):** helpers (`seed_from_string`, `kfold_indices`, `mse`, `fit_ols`, `predict`), plotting scaffolds, and data generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ea36a0f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple, List\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8, 4)\n",
        "plt.rcParams['axes.spines.top'] = False\n",
        "plt.rcParams['axes.spines.right'] = False\n",
        "plt.rcParams['figure.dpi'] = 120\n",
        "\n",
        "def seed_from_string(s: str) -> int:\n",
        "    import hashlib\n",
        "    h = hashlib.sha256(s.encode('utf-8')).digest()\n",
        "    return int.from_bytes(h[:4], 'little', signed=False)\n",
        "\n",
        "def train_test_split(X, y, train_frac=0.8, shuffle=True, seed=0):\n",
        "    n = len(y)\n",
        "    idx = np.arange(n)\n",
        "    if shuffle:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        rng.shuffle(idx)\n",
        "    cut = int(train_frac*n)\n",
        "    tr, te = idx[:cut], idx[cut:]\n",
        "    return X[tr], X[te], y[tr], y[te]\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    return float(np.mean((y_true - y_pred)**2))\n",
        "\n",
        "def kfold_indices(n, k=5, seed=0):\n",
        "    idx = np.arange(n)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    rng.shuffle(idx)\n",
        "    folds = np.array_split(idx, k)\n",
        "    return folds\n",
        "\n",
        "def fit_ols(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
        "    # Closed-form least squares using pinv for stability.\n",
        "    return np.linalg.pinv(X) @ y\n",
        "\n",
        "def predict(X: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
        "    return X @ w"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "627380bf",
      "metadata": {},
      "source": [
        "## Part 1 — Create your **multi‑cycle** dataset (unique per student)\n",
        "\n",
        "We model\n",
        "\n",
        "$y(t) = \\alpha_0 + \\alpha_1 t + A \\sin(\\omega t + \\phi) + \\epsilon,\\quad \\epsilon\\sim \\mathcal{N}(0,\\sigma^2). $\n",
        "\n",
        "Target **4–8 cycles**. Use your CUNY email or EMPLID as the RNG seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a35cdbc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_dataset(student_key: str,\n",
        "                     n_points: int = 400,\n",
        "                     t_span: Tuple[float, float] = (0.0, 40.0),\n",
        "                     min_cycles: float = 4.0,\n",
        "                     max_cycles: float = 8.0,\n",
        "                     noise_sigma: float = 0.15,\n",
        "                     trend_mag: float = 0.03):\n",
        "    seed = seed_from_string(student_key)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    t0, t1 = t_span\n",
        "    t = np.linspace(t0, t1, n_points)\n",
        "    total_cycles = rng.uniform(min_cycles, max_cycles)\n",
        "    omega = 2*np.pi*total_cycles/(t1 - t0)\n",
        "    A = rng.uniform(0.8, 1.2)\n",
        "    phi = rng.uniform(-np.pi, np.pi)\n",
        "    alpha0 = rng.uniform(-0.5, 0.5)\n",
        "    alpha1 = rng.uniform(-trend_mag, trend_mag)\n",
        "    eps = rng.normal(0.0, noise_sigma, size=n_points)\n",
        "    y = alpha0 + alpha1*t + A*np.sin(omega*t + phi) + eps\n",
        "    truth = dict(A=A, omega=omega, phi=phi, alpha0=alpha0, alpha1=alpha1, sigma=noise_sigma)\n",
        "    return t, y, truth\n",
        "\n",
        "# TODO: Replace with your CUNY email/EMPLID for a unique dataset\n",
        "STUDENT_KEY = \"firstname.lastname@cuny.edu\"\n",
        "\n",
        "t, y, truth = generate_dataset(STUDENT_KEY)\n",
        "print(\"truth (shown for learning; grading will use hidden seeds):\", truth)\n",
        "\n",
        "plt.plot(t, y, '.', label='observed')\n",
        "plt.xlabel(\"t\"); plt.ylabel(\"y\"); plt.legend(); plt.title(\"Your unique dataset\"); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d07734b",
      "metadata": {},
      "source": [
        "### What is K-fold Cross-Validation (CV)?\n",
        "\n",
        "**Goal.** Use all of the data without training and testing on overlapping samples. \n",
        "Cross-validation is used to select the best model from a set of candidates. \n",
        "\n",
        "**K-fold CV.** \n",
        "- Randomly partition indices into $K$ folds (equal sized chunks).\n",
        "- For each fold $j$: train the model on all examples except for the ones in fold $j$.\n",
        "- Take the trained model and apply it to the examples in fold $j$. Store the performance and repeat for all $K$ folds. \n",
        "\n",
        "**In this HW.**\n",
        "- Use `kfold_indices(n, k=5, seed=...)` once to get folds.\n",
        "- For each candidate model: loop folds → fit on $K-1$ folds, score on the held-out fold, **store** MSEs → average them.\n",
        "- Pick the candidate model with the **lowest** mean validation MSE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0f123bd",
      "metadata": {},
      "source": [
        "## Part 2 — Baseline: polynomial regression & **your** CV loop\n",
        "\n",
        "Implement `poly_features` and compose a k‑fold CV loop (not a helper function).\n",
        "- Degrees: 1..12\n",
        "- Use `kfold_indices(n, k=5, seed=...)` to make folds\n",
        "- For each degree, compute **train** and **validation** MSE and store them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93fda793",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# === STUDENT TODO (implement this function) ===\n",
        "def poly_features(x: np.ndarray, degree: int, include_bias=True) -> np.ndarray:\n",
        "    # Return design matrix [1, x, x^2, ..., x^degree] if include_bias=True,\n",
        "    # else [x, x^2, ..., x^degree].\n",
        "    # TODO(Student): implement and return an array of shape (n_samples, degree+include_bias)\n",
        "    raise NotImplementedError(\"Implement poly_features\")\n",
        "\n",
        "degrees = list(range(1, 13))\n",
        "cv_seed = seed_from_string(STUDENT_KEY) ^ 0xABCDEF\n",
        "k = 5\n",
        "\n",
        "train_mse_per_deg = []\n",
        "val_mse_per_deg = []\n",
        "\n",
        "# === STUDENT TODO: Compose the CV loop using kfold_indices ===\n",
        "# Outline:\n",
        "# 1) Build X for the current degree\n",
        "# 2) Get folds = kfold_indices(len(t), k=k, seed=cv_seed)\n",
        "# 3) For each fold, fit on union of others (fit_ols), score on that fold\n",
        "# 4) Store mean train MSE and mean val MSE for this degree\n",
        "for d in degrees:\n",
        "    # TODO(Student): build X for degree d\n",
        "    # TODO(Student): get folds\n",
        "    # TODO(Student): loop folds, split indices, fit and compute MSEs\n",
        "    # TODO(Student): append the mean train/val MSE to the lists\n",
        "    raise NotImplementedError(\"Compose the CV loop and record MSEs\")\n",
        "\n",
        "# === Plotting (leave as-is) ===\n",
        "best_degree_idx = int(np.argmin(val_mse_per_deg))\n",
        "best_degree = degrees[best_degree_idx]\n",
        "print(\"Best degree by CV:\", best_degree)\n",
        "\n",
        "# Fit a model at the selected degree on all data (for visualization)\n",
        "X_full = poly_features(t, best_degree, include_bias=True)\n",
        "w_full = fit_ols(X_full, y)\n",
        "yhat = predict(X_full, w_full)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(t, y, '.', label='observed')\n",
        "plt.plot(t, yhat, '-', label=f'poly deg={best_degree}')\n",
        "plt.xlabel(\"t\"); plt.ylabel(\"y\"); plt.legend(); plt.title(\"Polynomial fit\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(degrees, train_mse_per_deg, '-o', label='train MSE')\n",
        "plt.plot(degrees, val_mse_per_deg, '-o', label='CV MSE')\n",
        "plt.xlabel(\"degree\"); plt.ylabel(\"MSE\"); plt.legend(); plt.title(\"Polynomial selection by CV\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Discussion prompt: why do polynomials fail to capture multi-cycle periodicity here?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b2ee017",
      "metadata": {},
      "source": [
        "## Part 3 — Fourier features with **ridge** (parts supplied by you)\n",
        "\n",
        "You will write:\n",
        "- `fourier_features` (no linear trend; bias optional only)\n",
        "- Parts of `cv_ridge` to accumulate fold MSEs and choose the best α\n",
        "\n",
        "\n",
        "How to build the sinusoidal (Fourier) design matrix:\n",
        "    - Rows = samples. Each row corresponds to one time point in your data (e.g., t[i]).\n",
        "    - Columns = features. We’ll use a bias column (all ones) plus pairs of sine/cosine columns for each candidate frequency in your grid.\n",
        "\n",
        "Column order (must be exactly this):\n",
        "\n",
        "[ 1 , cos(ω0 * t) , sin(ω0 * t) , cos(ω1 * t) , sin(ω1 * t) , ... ]\n",
        "\n",
        "    - If you have n samples and m frequencies, the matrix shape is n x (1 + 2*m).\n",
        "    - We keep the bias in column 0 on purpose, so later we can easily find the cosine/sine weights for frequency j at positions offset + 2*j and offset + 2*j + 1 with offset = 1.\n",
        "\n",
        "\n",
        "Implementation tips:\n",
        "    - Start a list of columns with the bias: cols = [np.ones_like(t).reshape(-1,1)].\n",
        "    - For each frequency w in your grid:\n",
        "        - compute np.cos(w*t) and np.sin(w*t),\n",
        "        - reshape to column vectors (e.g., .reshape(-1,1)),\n",
        "        - append them to cols.\n",
        "    - Finish with X = np.hstack(cols).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145f4a03",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# === STUDENT TODO (implement this function) ===\n",
        "def fourier_features(t: np.ndarray, omegas: np.ndarray, include_bias: bool = True) -> np.ndarray:\n",
        "    # Build columns: [1] (optional), then for each ω_j in omegas: [cos(ω_j t), sin(ω_j t)].\n",
        "    # TODO(Student): implement; shape should be (n_samples, (1 if bias else 0) + 2*len(omegas))\n",
        "    raise NotImplementedError(\"Implement fourier_features\")\n",
        "\n",
        "def fit_ridge(X: np.ndarray, y: np.ndarray, alpha: float) -> np.ndarray:\n",
        "    XT_X = X.T @ X\n",
        "    I = np.eye(X.shape[1])\n",
        "    I[0, 0] = 0.0  # do not penalize bias\n",
        "    A = XT_X + alpha*I\n",
        "    return np.linalg.pinv(A) @ (X.T @ y)\n",
        "\n",
        "def cv_ridge(X: np.ndarray, y: np.ndarray, alphas: List[float], k=5, seed=0):\n",
        "    folds = kfold_indices(len(y), k=k, seed=seed)\n",
        "    mean_mse_per_alpha = []\n",
        "    for a in alphas:\n",
        "        fold_mses = []\n",
        "        for i in range(k):\n",
        "            va_idx = folds[i]\n",
        "            tr_idx = np.concatenate([folds[j] for j in range(k) if j != i])\n",
        "            w = fit_ridge(X[tr_idx], y[tr_idx], alpha=a)\n",
        "            # === STUDENT TODO: compute validation MSE for this fold and append ===\n",
        "            # Replace the next line with the correct MSE computation\n",
        "            fold_mses.append(0.0)\n",
        "        # === STUDENT TODO: append the mean of fold_mses to mean_mse_per_alpha ===\n",
        "        mean_mse_per_alpha.append(0.0)\n",
        "    # === STUDENT TODO: choose best_alpha (argmin over mean_mse_per_alpha) ===\n",
        "    best_alpha = float(alphas[0])\n",
        "    return best_alpha, mean_mse_per_alpha\n",
        "\n",
        "# Build frequency grid and run\n",
        "span = float(t[-1] - t[0])\n",
        "omega_grid = 2*np.pi*np.linspace(2.0, 14.0, 120)/span\n",
        "\n",
        "Xf = fourier_features(t, omega_grid, include_bias=True)\n",
        "alphas = np.logspace(-6, 2, 16)\n",
        "\n",
        "best_alpha, alpha_curve = cv_ridge(Xf, y, alphas, k=5, seed=seed_from_string(STUDENT_KEY)^0x55AA)\n",
        "print(\"Best alpha:\", best_alpha)\n",
        "\n",
        "wf = fit_ridge(Xf, y, alpha=best_alpha)\n",
        "yhat_f = Xf @ wf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(t, y, '.', label='observed')\n",
        "plt.plot(t, yhat_f, '-', label='Fourier+ridge')\n",
        "plt.xlabel(\"t\"); plt.ylabel(\"y\"); plt.legend(); plt.title(\"Fourier basis reconstruction\")\n",
        "plt.show()\n",
        "\n",
        "# Rank frequencies by amplitude sqrt(cos^2 + sin^2)\n",
        "offset = 1  # bias only (no trend)\n",
        "amps = []\n",
        "for j, w in enumerate(omega_grid):\n",
        "    c = wf[offset + 2*j]      # cos coeff\n",
        "    s = wf[offset + 2*j + 1]  # sin coeff\n",
        "    amps.append((float(np.sqrt(c*c + s*s)), float(w)))\n",
        "amps_sorted = sorted(amps, key=lambda x: -x[0])\n",
        "top3 = amps_sorted[:3]\n",
        "print(\"Top-3 frequency estimates (amplitude, omega):\", top3)\n",
        "\n",
        "print(\"Answer prompt: Compare your top-3 ω to the true ω in `truth`. Discuss grid resolution and ridge effects.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appendix — AI Log (required **only** if you used an LLM)\n",
        "Paste your prompts and briefly note what you used them for."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
