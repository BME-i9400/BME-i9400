{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BME i9400 \u2014 Homework: Learning Periodic Structure Beyond Polynomials\n",
        "**Assigned:** 2025-10-06  \n",
        "**Due:** _enter due date here_\n",
        "\n",
        "**Learning goals**\n",
        "- Understand **why** polynomial regression fails on multi\u2011cycle periodic data.\n",
        "- Implement **your own cross\u2011validation loop** using provided k\u2011fold indices.\n",
        "- Build sinusoidal/Fourier feature bases and use **ridge regression** with CV.\n",
        "- Communicate modeling choices via a short **Modeling Diary**.\n",
        "\n",
        "**Honor & AI use policy (read carefully)**\n",
        "- You may use docs/StackOverflow for syntax.  \n",
        "- You **may** ask an LLM for debugging/snippets, but you must include an **AI Log** at the end (prompts + what you used).\n",
        "- You **may not** ask for a full solution. Your code and plots must reflect your own understanding.\n",
        "- Brief spot\u2011checks (1\u20132 students) may be done in class.\n",
        "\n",
        "**Deliverables**\n",
        "1. Executed notebook (.ipynb) with all cells run.  \n",
        "2. `diary.pdf` (\u22641 page).  \n",
        "3. `ai_log.md` (if you used an LLM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**What YOU write (student-supplied code):**\n",
        "- `poly_features`\n",
        "- The **cross\u2011validation loop** for polynomials (store per\u2011degree train/val MSEs)\n",
        "- `fourier_features` (no trend; bias optional)\n",
        "- **One line** inside `fit_ridge` (add \u03b1 to diagonal; bias unpenalized)\n",
        "- Parts of `cv_ridge` (append fold MSEs; record means; choose best \u03b1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Provided (do not change):** helpers (`seed_from_string`, `kfold_indices`, `mse`, `fit_ols`, `predict`), plotting scaffolds, and data generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Tuple, List\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (8, 4)\n",
        "plt.rcParams['axes.spines.top'] = False\n",
        "plt.rcParams['axes.spines.right'] = False\n",
        "plt.rcParams['figure.dpi'] = 120\n",
        "\n",
        "def seed_from_string(s: str) -> int:\n",
        "    import hashlib\n",
        "    h = hashlib.sha256(s.encode('utf-8')).digest()\n",
        "    return int.from_bytes(h[:4], 'little', signed=False)\n",
        "\n",
        "def train_test_split(X, y, train_frac=0.8, shuffle=True, seed=0):\n",
        "    n = len(y)\n",
        "    idx = np.arange(n)\n",
        "    if shuffle:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        rng.shuffle(idx)\n",
        "    cut = int(train_frac*n)\n",
        "    tr, te = idx[:cut], idx[cut:]\n",
        "    return X[tr], X[te], y[tr], y[te]\n",
        "\n",
        "def mse(y_true, y_pred):\n",
        "    return float(np.mean((y_true - y_pred)**2))\n",
        "\n",
        "def kfold_indices(n, k=5, seed=0):\n",
        "    idx = np.arange(n)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    rng.shuffle(idx)\n",
        "    folds = np.array_split(idx, k)\n",
        "    return folds\n",
        "\n",
        "def fit_ols(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
        "    # Closed-form least squares using pinv for stability.\n",
        "    return np.linalg.pinv(X) @ y\n",
        "\n",
        "def predict(X: np.ndarray, w: np.ndarray) -> np.ndarray:\n",
        "    return X @ w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1 \u2014 Create your **multi\u2011cycle** dataset (unique per student)\n",
        "\n",
        "We model:\n",
        "\\[\n",
        "y(t) = \\alpha_0 + \\alpha_1 t + A \\sin(\\omega t + \\phi) + \\epsilon,\\quad \\epsilon\\sim \\mathcal{N}(0,\\sigma^2).\n",
        "\\]\n",
        "Target **4\u20138 cycles**. Use your CUNY email or EMPLID as the RNG seed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_dataset(student_key: str,\n",
        "                     n_points: int = 400,\n",
        "                     t_span: Tuple[float, float] = (0.0, 40.0),\n",
        "                     min_cycles: float = 4.0,\n",
        "                     max_cycles: float = 8.0,\n",
        "                     noise_sigma: float = 0.15,\n",
        "                     trend_mag: float = 0.03):\n",
        "    seed = seed_from_string(student_key)\n",
        "    rng = np.random.default_rng(seed)\n",
        "    t0, t1 = t_span\n",
        "    t = np.linspace(t0, t1, n_points)\n",
        "    total_cycles = rng.uniform(min_cycles, max_cycles)\n",
        "    omega = 2*np.pi*total_cycles/(t1 - t0)\n",
        "    A = rng.uniform(0.8, 1.2)\n",
        "    phi = rng.uniform(-np.pi, np.pi)\n",
        "    alpha0 = rng.uniform(-0.5, 0.5)\n",
        "    alpha1 = rng.uniform(-trend_mag, trend_mag)\n",
        "    eps = rng.normal(0.0, noise_sigma, size=n_points)\n",
        "    y = alpha0 + alpha1*t + A*np.sin(omega*t + phi) + eps\n",
        "    truth = dict(A=A, omega=omega, phi=phi, alpha0=alpha0, alpha1=alpha1, sigma=noise_sigma)\n",
        "    return t, y, truth\n",
        "\n",
        "# TODO: Replace with your CUNY email/EMPLID for a unique dataset\n",
        "STUDENT_KEY = \"firstname.lastname@cuny.edu\"\n",
        "\n",
        "t, y, truth = generate_dataset(STUDENT_KEY)\n",
        "print(\"truth (shown for learning; grading will use hidden seeds):\", truth)\n",
        "\n",
        "plt.plot(t, y, '.', label='observed')\n",
        "plt.xlabel(\"t\"); plt.ylabel(\"y\"); plt.legend(); plt.title(\"Your unique dataset\"); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is K-fold Cross-Validation (CV)?\n",
        "\n",
        "**Goal.** Estimate out-of-sample error and compare hyperparameters (e.g., degree \\(d\\), ridge \\(\\alpha\\)) **without** a separate validation set.\n",
        "\n",
        "**K-fold CV.** Randomly partition indices into \\(K\\) folds \\(S_1,\\dots,S_K\\). For each fold \\(j\\): train on \\(\\mathcal{D}\\setminus S_j\\), validate on \\(S_j\\), record the loss. The \\(K\\)-fold estimate for a setting \\(\\lambda\\) is\n",
        "\\[\n",
        "\\text{CV}_K(\\lambda)=\\frac{1}{K}\\sum_{j=1}^K \\frac{1}{|S_j|}\\sum_{i\\in S_j}\\ell\\big(y_i,\\hat f_{\\lambda}^{(-j)}(x_i)\\big).\n",
        "\\]\n",
        "\n",
        "**In this HW.**\n",
        "- Use `kfold_indices(n, k=5, seed=...)` once to get folds.\n",
        "- For each candidate: loop folds \u2192 fit on \\(K-1\\) folds, score on the held-out fold, **store** MSEs \u2192 average them.\n",
        "- Pick the candidate with the **lowest** mean validation MSE.\n",
        "\n",
        "**Good habits.** Fix folds across candidates (same seed), avoid leakage, typical \\(K=5\\) or \\(10\\)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2 \u2014 Baseline: polynomial regression & **your** CV loop\n",
        "\n",
        "Implement `poly_features` and compose a k\u2011fold CV loop (not a helper function).\n",
        "- Degrees: 1..12\n",
        "- Use `kfold_indices(n, k=5, seed=...)` to make folds\n",
        "- For each degree, compute **train** and **validation** MSE and store them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# === STUDENT TODO (implement this function) ===\n",
        "def poly_features(x: np.ndarray, degree: int, include_bias=True) -> np.ndarray:\n",
        "    # Return design matrix [1, x, x^2, ..., x^degree] if include_bias=True,\n",
        "    # else [x, x^2, ..., x^degree].\n",
        "    # TODO(Student): implement and return an array of shape (n_samples, degree+include_bias)\n",
        "    raise NotImplementedError(\"Implement poly_features\")\n",
        "\n",
        "degrees = list(range(1, 13))\n",
        "cv_seed = seed_from_string(STUDENT_KEY) ^ 0xABCDEF\n",
        "k = 5\n",
        "\n",
        "train_mse_per_deg = []\n",
        "val_mse_per_deg = []\n",
        "\n",
        "# === STUDENT TODO: Compose the CV loop using kfold_indices ===\n",
        "# Outline:\n",
        "# 1) Build X for the current degree\n",
        "# 2) Get folds = kfold_indices(len(t), k=k, seed=cv_seed)\n",
        "# 3) For each fold, fit on union of others (fit_ols), score on that fold\n",
        "# 4) Store mean train MSE and mean val MSE for this degree\n",
        "for d in degrees:\n",
        "    # TODO(Student): build X for degree d\n",
        "    # TODO(Student): get folds\n",
        "    # TODO(Student): loop folds, split indices, fit and compute MSEs\n",
        "    # TODO(Student): append the mean train/val MSE to the lists\n",
        "    raise NotImplementedError(\"Compose the CV loop and record MSEs\")\n",
        "\n",
        "# === Plotting (leave as-is) ===\n",
        "best_degree_idx = int(np.argmin(val_mse_per_deg))\n",
        "best_degree = degrees[best_degree_idx]\n",
        "print(\"Best degree by CV:\", best_degree)\n",
        "\n",
        "# Fit a model at the selected degree on all data (for visualization)\n",
        "X_full = poly_features(t, best_degree, include_bias=True)\n",
        "w_full = fit_ols(X_full, y)\n",
        "yhat = predict(X_full, w_full)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(t, y, '.', label='observed')\n",
        "plt.plot(t, yhat, '-', label=f'poly deg={best_degree}')\n",
        "plt.xlabel(\"t\"); plt.ylabel(\"y\"); plt.legend(); plt.title(\"Polynomial fit\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(degrees, train_mse_per_deg, '-o', label='train MSE')\n",
        "plt.plot(degrees, val_mse_per_deg, '-o', label='CV MSE')\n",
        "plt.xlabel(\"degree\"); plt.ylabel(\"MSE\"); plt.legend(); plt.title(\"Polynomial selection by CV\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Discussion prompt: why do polynomials fail to capture multi-cycle periodicity here?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 3 \u2014 Fourier features with **ridge** (parts supplied by you)\n",
        "\n",
        "You will write:\n",
        "- `fourier_features` (no linear trend; bias optional only)\n",
        "- **One line** inside `fit_ridge` (add \u03b1 to the diagonal, but **do not** regularize the bias column)\n",
        "- Parts of `cv_ridge` to accumulate fold MSEs and choose the best \u03b1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# === STUDENT TODO (implement this function) ===\n",
        "def fourier_features(t: np.ndarray, omegas: np.ndarray, include_bias: bool = True) -> np.ndarray:\n",
        "    # Build columns: [1] (optional), then for each \u03c9_j in omegas: [cos(\u03c9_j t), sin(\u03c9_j t)].\n",
        "    # TODO(Student): implement; shape should be (n_samples, (1 if bias else 0) + 2*len(omegas))\n",
        "    raise NotImplementedError(\"Implement fourier_features\")\n",
        "\n",
        "def fit_ridge(X: np.ndarray, y: np.ndarray, alpha: float) -> np.ndarray:\n",
        "    # Closed-form ridge: w = (X^T X + \u03b1 I)^(-1) X^T y.\n",
        "    # IMPORTANT: Do NOT regularize the bias column (assume it's the first column).\n",
        "    XT_X = X.T @ X\n",
        "    I = np.eye(X.shape[1])\n",
        "    # Do not regularize bias\n",
        "    I[0, 0] = 0.0\n",
        "\n",
        "    # === STUDENT TODO (single line): add \u03b1 to the diagonal before inverting ===\n",
        "    # Replace ??? with the correct expression\n",
        "    A = ???\n",
        "\n",
        "    return np.linalg.pinv(A) @ (X.T @ y)\n",
        "\n",
        "def cv_ridge(X: np.ndarray, y: np.ndarray, alphas: List[float], k=5, seed=0):\n",
        "    folds = kfold_indices(len(y), k=k, seed=seed)\n",
        "    mean_mse_per_alpha = []\n",
        "    for a in alphas:\n",
        "        fold_mses = []\n",
        "        for i in range(k):\n",
        "            va_idx = folds[i]\n",
        "            tr_idx = np.concatenate([folds[j] for j in range(k) if j != i])\n",
        "            w = fit_ridge(X[tr_idx], y[tr_idx], alpha=a)\n",
        "            # === STUDENT TODO: compute validation MSE for this fold and append ===\n",
        "            # Replace the next line with the correct MSE computation\n",
        "            fold_mses.append(0.0)\n",
        "        # === STUDENT TODO: append the mean of fold_mses to mean_mse_per_alpha ===\n",
        "        mean_mse_per_alpha.append(0.0)\n",
        "    # === STUDENT TODO: choose best_alpha (argmin over mean_mse_per_alpha) ===\n",
        "    best_alpha = float(alphas[0])\n",
        "    return best_alpha, mean_mse_per_alpha\n",
        "\n",
        "# Build frequency grid and run\n",
        "span = float(t[-1] - t[0])\n",
        "omega_grid = 2*np.pi*np.linspace(2.0, 14.0, 120)/span\n",
        "\n",
        "Xf = fourier_features(t, omega_grid, include_bias=True)\n",
        "alphas = np.logspace(-6, 2, 16)\n",
        "\n",
        "best_alpha, alpha_curve = cv_ridge(Xf, y, alphas, k=5, seed=seed_from_string(STUDENT_KEY)^0x55AA)\n",
        "print(\"Best alpha:\", best_alpha)\n",
        "\n",
        "wf = fit_ridge(Xf, y, alpha=best_alpha)\n",
        "yhat_f = Xf @ wf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(t, y, '.', label='observed')\n",
        "plt.plot(t, yhat_f, '-', label='Fourier+ridge')\n",
        "plt.xlabel(\"t\"); plt.ylabel(\"y\"); plt.legend(); plt.title(\"Fourier basis reconstruction\")\n",
        "plt.show()\n",
        "\n",
        "# Rank frequencies by amplitude sqrt(cos^2 + sin^2)\n",
        "offset = 1  # bias only (no trend)\n",
        "amps = []\n",
        "for j, w in enumerate(omega_grid):\n",
        "    c = wf[offset + 2*j]      # cos coeff\n",
        "    s = wf[offset + 2*j + 1]  # sin coeff\n",
        "    amps.append((float(np.sqrt(c*c + s*s)), float(w)))\n",
        "amps_sorted = sorted(amps, key=lambda x: -x[0])\n",
        "top3 = amps_sorted[:3]\n",
        "print(\"Top-3 frequency estimates (amplitude, omega):\", top3)\n",
        "\n",
        "print(\"Answer prompt: Compare your top-3 \u03c9 to the true \u03c9 in `truth`. Discuss grid resolution and ridge effects.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 4 \u2014 Reflection (for your Modeling Diary)\n",
        "\n",
        "- Why do polynomials overfit/extrapolate poorly on periodic signals across many cycles?\n",
        "- How did ridge regularization change your Fourier solution (bias\u2013variance, leakage)?\n",
        "- If two close frequencies were present, what would you change (features, grid density, regularization)?\n",
        "- (Optional) Try random Fourier features or a periodic kernel (GP) and comment qualitatively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appendix \u2014 AI Log (required **only** if you used an LLM)\n",
        "Paste your prompts and briefly note what you used them for."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}