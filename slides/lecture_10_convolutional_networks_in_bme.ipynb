{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c19199",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## BME i9400\n",
    "## Fall 2024\n",
    "### Applications of Machine Learning to BME\n",
    "#### Convolutional Neural Networks in EEG classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7001d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review of the previous lecture\n",
    "- Convolutional neural networks employ *weight sharing* by sliding *filters* across the input data\n",
    "- Can be 1D, 2D, or 3D depending on the data\n",
    "- Typically employ *pooling* operations to progressively reduce the size of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28273e61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1D Convolution\n",
    "<img src=\"conv1d.jpeg\" alt=\"1D Convolution\" width=\"1200\"/>\n",
    "\n",
    "### 2D Convolution\n",
    "<img src=\"conv2d.jpeg\" alt=\"2D Convolution\" width=\"1200\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d84abb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A Typical CNN\n",
    "<img src=\"conv.png\" alt=\"ANN Diagram\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e1dd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstrating convolutional neural networks for EEG classification\n",
    "- CNNs are often used in biomedical applications due to their ability to learn spatial and temporal patterns in data\n",
    "- An example of a spatiotemporal dataset is the electroencephalogram (EEG), which records electrical activity in the brain over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cf6cc5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is EEG?\n",
    "- EEG is a non-invasive brain imaging technique that records the brain's natural electrical activity\n",
    "- Electrodes are placed on the scalp and capture small voltages that fluctuate over time\n",
    "    - These fluctuations carry information about the state of the brain\n",
    "\n",
    "<img src=\"eeg.webp\" alt=\"ANN Diagram\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ea6dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The EEG can be represented as a 2D matrix (image)\n",
    "- Each electrode on the scalp records a time series of electrical activity\n",
    "- Collectively, these time series form a 2D matrix, where one dimension represents the electrodes and the other dimension represents the time points\n",
    "    - The rows of the matrix represent the electrodes\n",
    "    - The columns of the matrix represent the time points\n",
    "- As a result, we can apply convolutional layers to capture spatial and temporal patterns in the EEG data\n",
    "    - Note however that the nature of rows (electrodes) and columns (samples) are different from images, where both rows and columns correspond to pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91f7a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## EEG dataset\n",
    "- The dataset that we will be working with is available on [Kaggle](https://www.kaggle.com/datasets/nnair25/Alcoholics/data)\n",
    "- This dataset arises from a research study that examines EEG correlates of genetic predisposition to alcoholism\n",
    "- Each example consists of data measured at 64 scalp electrodes, with the voltages collected for 1 sec with a 256 Hz sampling rate\n",
    "- Subjects have been divided into two groups: alcoholic and control\n",
    "- Subjects were shown pictures of objects from a picture set, either a single stimulus or two stimuli in a matched or non-matched condition\n",
    "- The primary purpose of the stimuli is to elicit brain activity from subjects in a reproducible condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d54d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objective of the CNN\n",
    "- The objective of the model that we will build is to discriminate the brain activity of alcoholics from that of control subjects\n",
    "- The information that discriminates subjects may either be represented as patterns across *space* (across electrodes) or across *time* (across time points)\n",
    "- Therefore, we would like our model to be able to capture both spatial and temporal patterns in the EEG data\n",
    "- We will therefore use an initial spatial convolutional layer followed by a temporal convolutional layer\n",
    "- Finally, we will use a dense layer to classify the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87883e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "eedb6ea4",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "533b20a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the dataset\n",
    "- The dataset has been preprocessed and stored in a numpy file\n",
    "    - The code for generating the dataset is provided at the end of this notebook\n",
    "- The data is stored in a dictionary with keys `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "id": "42fbbb03",
   "metadata": {},
   "source": [
    "tmp = np.load('eeg_alcohol_data.npy', allow_pickle=True)\n",
    "X = tmp.item().get('X')\n",
    "y = tmp.item().get('y')\n",
    "X.shape, y.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a45bdcd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examining the data\n",
    "- Let's look at a few examples from the dataset\n",
    "- We will visualize the space-time matrix of EEG"
   ]
  },
  {
   "cell_type": "code",
   "id": "96392c55",
   "metadata": {},
   "source": [
    "trial_index = 0\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "ax[0].imshow(X[trial_index], aspect='auto', cmap='jet')\n",
    "ax[0].set_xlabel('Time samples')\n",
    "ax[0].set_ylabel('Electrodes')\n",
    "\n",
    "ax[1].plot(X[trial_index,::4,:].T)\n",
    "ax[1].set_xlabel('Time samples')\n",
    "ax[1].set_ylabel('Voltage')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "22d63cdb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data preprocessing and splitting\n",
    "- As we will be working with PyTorch, we need to convert our native Numpy data to PyTorch tensor format\n",
    "- We will also split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "id": "e618a216",
   "metadata": {},
   "source": [
    "# Ensure X is a numpy array of float32\n",
    "if X.dtype != np.float32:\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "\n",
    "# Ensure y is a numpy array of integers\n",
    "if y.dtype not in [np.int32, np.int64]:\n",
    "    y = np.array(y, dtype=np.int64)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "73374fa6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining the model architecture\n",
    "- We will define a simple CNN model with two convolutional layers and a dense layer\n",
    "- The first convolutional layer will be spatial, filtering across the electrodes\n",
    "    - The kernel here will have a size of (64, 1)\n",
    "    - We will learn 16 such filters (each filter will be applied to all electrodes but capture different spatial patterns)\n",
    "- The second convolutional layer will be temporal, filtering across the time points\n",
    "    - Note that these temporal filters will now be applied on top of the spatially filtered data!\n",
    "    - The kernel here will have a size of (1, 10) with a stride of 2 (our filter has a length of 10 samples and we will slide it by 2 samples at a time)\n",
    "- We then flatten the output of the second convolutional layer to create a single long vector\n",
    "- Finally, we pass this vector through a dense layer that has 2 outputs, one for each class\n",
    "- We will use the softmax activation function to convert the output of the dense layer to probabilities"
   ]
  },
  {
   "cell_type": "code",
   "id": "29aa6892",
   "metadata": {},
   "source": [
    "# Define the CNN model\n",
    "class EEGCNN(nn.Module):\n",
    "    def __init__(self, input_channels, input_timepoints, num_classes):\n",
    "        super(EEGCNN, self).__init__()\n",
    "        self.spatial_conv = nn.Conv2d(1, 16, kernel_size=(input_channels, 1))  # Spatial filtering\n",
    "        self.temporal_conv = nn.Conv2d(16, 32, kernel_size=(1, 10), stride=(1, 2))  # Temporal filtering\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32 * ((input_timepoints - 10) // 2 + 1), num_classes)  # Dense layer\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = torch.relu(self.spatial_conv(x))\n",
    "        x = torch.relu(self.temporal_conv(x))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d07f178c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Instantiating the model\n",
    "- Although we have defined the architecture, we have not yet instantiated the model\n",
    "- We will do so now by telling the model how many input channels, time points, and classes it should expect"
   ]
  },
  {
   "cell_type": "code",
   "id": "dee80b34",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Initialize the model\n",
    "input_channels = X_train.shape[1]  # 64 electrodes\n",
    "input_timepoints = X_train.shape[2]  # 256 time samples\n",
    "num_classes = len(torch.unique(y_train))  # Number of unique classes in y\n",
    "model = EEGCNN(input_channels, input_timepoints, num_classes)\n",
    "print(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c74e5d7a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyTorch dataloaders\n",
    "- To train the model, we need to create *data loaders* that will feed the data to the model in batches\n",
    "- We will use the `TensorDataset` and `DataLoader` classes from PyTorch to create these data loaders"
   ]
  },
  {
   "cell_type": "code",
   "id": "f51c32cb",
   "metadata": {},
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e6a1efff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining the loss function and optimizer\n",
    "- As usual, we will use the cross-entropy loss function and the Adam optimizer\n",
    "- Remember that the Adam optimizer is a variant of stochastic gradient descent that is often used in deep learning"
   ]
  },
  {
   "cell_type": "code",
   "id": "307fa6da",
   "metadata": {},
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a956dac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's train the model!\n",
    "- We will train the model for 10 epochs (that is, we will pass through the entire training set 10 times in batches of 32)"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0e93255",
   "metadata": {},
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8794b4bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's evaluate the model\n",
    "- We first will pass through the test set and calculate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "019878ea",
   "metadata": {},
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_outputs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_outputs.append(outputs)\n",
    "        all_labels.append(y_batch)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6b8084f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How did we do relative to chance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24f2821",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's plot the ROC curve\n",
    "- We will need to assemble all predictions and labels on the test set\n",
    "- We will need to convert the PyTorch tensors to numpy arrays so that we can use the `roc_curve` and `auc` functions from `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee63671b",
   "metadata": {},
   "source": [
    "py_hat = torch.cat(all_outputs, dim=0)\n",
    "y_test = torch.cat(all_labels, dim=0)\n",
    "\n",
    "# cast to numpy\n",
    "py_hat = py_hat.numpy()\n",
    "y_test = y_test.numpy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "424262e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We are now ready to plot the ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "id": "27ef7cbb",
   "metadata": {},
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, py_hat[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dcfcfb4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Code for generating dataset below"
   ]
  },
  {
   "cell_type": "code",
   "id": "c7b394ac",
   "metadata": {},
   "source": [
    "import kagglehub\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_and_package_data():\n",
    "\n",
    "    path = kagglehub.dataset_download(\"nnair25/Alcoholics\")\n",
    "    print(\"Path to dataset files:\", path)\n",
    "\n",
    "    ##\n",
    "    _dfs_list = []\n",
    "    for csv_filename in tqdm(glob.glob(path+'/SMNI_CMI_TRAIN/*.csv')):\n",
    "        _dfs_list.append(pd.read_csv(csv_filename))\n",
    "    df = pd.concat(_dfs_list)\n",
    "    del(_dfs_list)\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    ##\n",
    "    channel_list = list(set(df['sensor position']))\n",
    "    channel_list.sort()\n",
    "\n",
    "    channel_mapping = {\n",
    "        'AFZ':'AFz',\n",
    "        'CPZ':'CPz',\n",
    "        'CZ':'Cz',\n",
    "        'FCZ':'FCz',\n",
    "        'FP1':'Fp1',\n",
    "        'FP2':'Fp2',\n",
    "        'FPZ':'Fpz',\n",
    "        'FZ':'Fz',\n",
    "        'OZ':'Oz',\n",
    "        'POZ':'POz',\n",
    "        'PZ':'Pz',\n",
    "    }\n",
    "\n",
    "    channel_mapping_full = dict()\n",
    "\n",
    "    for ch in channel_list:\n",
    "        if ch in channel_mapping:\n",
    "            channel_mapping_full[ch] = channel_mapping[ch]\n",
    "        else:\n",
    "            channel_mapping_full[ch] = ch\n",
    "\n",
    "    channel_list_fixed = [channel_mapping_full[ch] for ch in channel_list]\n",
    "\n",
    "    df['sensor position'] = df['sensor position'].map(channel_mapping_full)\n",
    "\n",
    "    # transpose the table to make the data extraction easier\n",
    "    transposed_df_list = []\n",
    "\n",
    "    for group_df in tqdm(df.groupby(['name', 'trial number', 'matching condition', 'sensor position', 'subject identifier'])):\n",
    "        _df = pd.DataFrame(group_df[1]['sensor value']).T\n",
    "        _df.columns = [f'sample_{idx}' for idx in range(256)]\n",
    "        _df['name'] = group_df[0][0]\n",
    "        _df['trial number'] = group_df[0][1]\n",
    "        _df['matching condition'] = group_df[0][2]\n",
    "        _df['sensor position'] = group_df[0][3]\n",
    "        _df['subject identifier'] = group_df[0][4]\n",
    "\n",
    "        transposed_df_list.append(_df)\n",
    "\n",
    "    df = pd.concat(transposed_df_list)\n",
    "    df = df[[*df.columns[-5:],*df.columns[0:-5]]]\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.head(3)\n",
    "\n",
    "    def get_record_df(df, name, trial_number, matching_condition, channel_list):\n",
    "        df_record = df[df['name'].eq(name) & df['trial number'].eq(trial_number) & df['matching condition'].eq(matching_condition)].set_index(['sensor position']).loc[channel_list]\n",
    "        return df_record\n",
    "\n",
    "    def get_signal_array(df, name, trial_number, matching_condition, channel_list):\n",
    "        df_record = get_record_df(df, name, trial_number, matching_condition, channel_list)\n",
    "        return df_record.to_numpy()[:, 4:]\n",
    "\n",
    "    all_signal_arrays = []\n",
    "    all_subject_ids = []\n",
    "    for name in df['name'].unique():\n",
    "        for trial_number in df[df['name'].eq(name)]['trial number'].unique():\n",
    "            for matching_condition in df[df['name'].eq(name) & df['trial number'].eq(trial_number)]['matching condition'].unique():\n",
    "                signal_array = get_signal_array(df, name, trial_number, matching_condition, channel_list_fixed)\n",
    "                all_signal_arrays.append(signal_array)\n",
    "                id = df[(df['name'].eq(name)) & (df['trial number'].eq(trial_number)) & (df['matching condition'].eq(matching_condition))]['subject identifier'].values[0]\n",
    "                all_subject_ids.append(id)\n",
    "\n",
    "    X = np.array(all_signal_arrays)\n",
    "    all_subject_ids_binary = [1 if id == 'a' else 0 for id in all_subject_ids]\n",
    "    y = np.array(all_subject_ids_binary)\n",
    "\n",
    "    return X, y"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
