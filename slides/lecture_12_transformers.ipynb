{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## BME i9400\n",
    "## Fall 2024\n",
    "### Transformers and Large Language Models"
   ],
   "id": "83d3aefbb035da77"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Goals of this Lecture\n",
    "\n",
    "1. Understand the fundamentals of the transformer architecture.\n",
    "2. Learn how the attention mechanism works and why it is central to transformers.\n",
    "3. Gain intuition about why transformers are so effective.\n",
    "4. Explore how transformers are used to build large language models through pretraining and fine-tuning."
   ],
   "id": "2189d41bbf4e5ebd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Some fantastic resources for understanding the Transformer architecture\n",
    "- Wrapping your head around transformers will take multiple passes. However, it is well worth the effort!\n",
    "- Some resources that I found particularly helpful:\n",
    "    - [Transformer Explainer](https://poloclub.github.io/transformer-explainer/)\n",
    "    - [Understanding self-attention](https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html)\n",
    "    - [3 Blue 1 Brown video on transformers](https://www.youtube.com/watch?v=eMlx5fFNoYc) "
   ],
   "id": "c6995b84bfd7d707"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The classic picture of the Transformer architecture\n",
    "- This is the picture that appears in the original paper by Vaswani et al. (2017).\n",
    "    - Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.\n",
    "- Despite appearing in the paper, it is not a good starting point for understanding transformers.\n",
    "- In fact the original paper is not a good resource for learning the architecture.\n",
    "- In the paper, transformers are mainly posed as a solution to machine translation: converting a sentence in one language to another.\n",
    "<img src=\"transformer.webp\" width=\"600\" height=\"600\">"
   ],
   "id": "f1277f6215329d31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What is a Transformer?\n",
    "- *Transformers* are a type of model architecture that has revolutionized natural language processing (NLP).\n",
    "- Key innovation: Self-attention mechanism for processing sequences.\n",
    "    - Replaced previous architectures that included convolutional neural nets (CNNs) models in NLP.\n",
    "- Enabled state-of-the-art performance in:\n",
    "    - Translation\n",
    "    - Summarization\n",
    "    - Question answering\n"
   ],
   "id": "24a9bf924047c759"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Transformer Architecture Overview\n",
    "- Composed of an encoder and decoder\n",
    "    - Encoder: Processes input sequences (i.e., English sentence)\n",
    "\t- Decoder: Generates output sequences (i.e., French translation)\n",
    "- Core components:\n",
    "\t1.\tSelf-Attention: Captures relationships between words in a sequence.\n",
    "\t2.\tFeedforward Layers: Nonlinear transformations for learning representations.\n",
    "\t3.\tPositional Encoding: Adds order information to the sequence.\n",
    "- Stacked layers of attention and feedforward modules allow deep learning."
   ],
   "id": "7bf724ba1536cc23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why Attention?\n",
    "\n",
    "- Attention allows the model to focus on relevant parts of the sequence.\n",
    "- Example: In a sentence, “The cat sat on the mat,” the word “cat” is strongly related to “sat.”\n",
    "- Attention weights capture these relationships.\n",
    "- Self-attention captures long-range dependencies better than previous approaches."
   ],
   "id": "416e57e81145b1bc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokenization, Embedding, Positional Encoding\n",
    "- To start, we convert the input sentence into a sequence of tokens\n",
    "- These tokens are initially represented by integers\n",
    "- We then convert these integers into dense vectors called *embeddings*\n",
    "- To capture the order of the tokens, we add *positional encodings* to the embeddings\n",
    "    - Positional encoding is a sine-cosine function of the position of the token in the sequence\n",
    "    - These sine-cosine functions are literally added to the embeddings\n",
    "<img src=\"embedding.png\" width=\"900\">"
   ],
   "id": "24ca8fa75ab4c633"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Attention Mechanism\n",
    "1.\tInput: A sequence of word embeddings.\n",
    "2.  Query, Key, Value (Q, K, V):\n",
    "    - Represent each word with three vectors.\n",
    "3. Attention Scores:\n",
    "\t    - Compute scores for each word using:\n",
    " \n",
    "___\n",
    "$ \\text{Score}(Q, K) = \\frac{Q \\cdot K^\\top}{\\sqrt{d_k}} $ \n",
    "___\n",
    "        \n",
    "4.  Apply softmax to normalize scores.\n",
    "5. Compute context vector as weighted summation of values:\n",
    "\t    - Combine values (V) weighted by attention scores.\n",
    "**The context vector is the output of the attention mechanism.**\n"
   ],
   "id": "4001365fa5515151"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Multi-Head Attention\n",
    "-   Splits attention into multiple “heads” for diverse perspectives.\n",
    "-   Each head independently computes attention, focusing on different relationships.\n",
    "-   Outputs are concatenated and linearly transformed.\n",
    "\n",
    "___ \n",
    "$\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\text{head}_2, \\ldots)W^O$\n",
    "\n",
    "___ \n",
    "<img src=\"QKV.png\" width=\"900\">\n"
   ],
   "id": "2ad591cce9834100"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Masked Self-Attention\n",
    "- Attention Score\n",
    "    - The dot product between all query-key pairs is computed and represents how much the quary is related to the key.\n",
    "- Masking\n",
    "    - A \"mask\" is applied to the matrix of attention scores so that the model is not able to see the future words (this would be cheating in the context of language modeling).\n",
    "- Softmax\n",
    "    - Attention scores are converted into probabilities using the softmax function.\n",
    "    - The resulting matrix elements represent how strongly each word relates to the words to its left. \n",
    "<img src=\"attention.png\" width=\"900\" >"
   ],
   "id": "96bc8e232d0b3e90"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Output of self-attention block\n",
    "- The (softmax-ed) self-attention scores are multiplied by the value matrix to produce the output of the self-attention block."
   ],
   "id": "7acb439ca185ed30"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feedforward Layer\n",
    "- The context vectors from the self-attention block are passed through a feedforward layer.\n",
    "- The task of this layer is to exploit the context of the sentence in order to predict the next word.\n",
    "- In the end, this results in a vector of probabilities, one for each token in the vocabulary.\n",
    "- The token with the highest probability is the predicted next word.\n",
    "<img src=\"mlp.png\" width=\"900\">"
   ],
   "id": "13485c5b835b85a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Why Are Transformers So Effective?\n",
    "-   Parallelization: Processes entire sequences simultaneously (vs. sequentially in RNNs).\n",
    "-   Scalability: Handles very large datasets and model sizes.\n",
    "-   Representation Power: Captures complex relationships with self-attention.\n",
    "-   Versatility: Works across various tasks with minimal architecture changes."
   ],
   "id": "c78b7a37eea3e8eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## How Are LLMs Built?\n",
    "\n",
    "-   Pretraining: train on massive corpora (e.g., books, biomedical papers).\n",
    "-   Pretraining tasks:\n",
    "    -   Masked language modeling (BERT).\n",
    "\t-   Autoregressive prediction (GPT).\n",
    "-   Fine-Tuning:\n",
    "    - Adapt pretrained models to specific tasks with smaller datasets (e.g., question answering)."
   ],
   "id": "60a601dfd8dbc05"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Transformers in Biomedical Engineering\n",
    "-\tLiterature mining: Extract disease-gene associations from PubMed abstracts.\n",
    "-   Clinical notes analysis: Summarize patient records or identify key trends.\n",
    "-\tDrug discovery: Predict drug-target interactions or design new molecules."
   ],
   "id": "36b1296c03f94d75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hands on demo with the Hugging Face Transformers library",
   "id": "510a91f46ab0202a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "# Load a pretrained masked language model\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "# Encode a sentence with a masked token\n",
    "text = \"The heart is a [MASK] organ.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Display the token IDs\n",
    "print(\"Input IDs:\", inputs.input_ids)"
   ],
   "id": "a6208a0f33a9ed25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate the mode's prediction for the masked token\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Get predicted token for the masked position\n",
    "predictions = outputs.logits\n",
    "mask_index = inputs.input_ids[0].tolist().index(tokenizer.mask_token_id)\n",
    "predicted_token_id = predictions[0, mask_index].argmax(dim=-1).item()\n",
    "print(\"Predicted Token:\", tokenizer.decode([predicted_token_id]))"
   ],
   "id": "85dc935a779fe3df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get the top 5 predictions\n",
    "top_k = 5\n",
    "top_predictions = predictions[0, mask_index].topk(top_k).indices\n",
    "top_predictions = [tokenizer.decode([token_id]) for token_id in top_predictions]\n",
    "print(\"Top Predictions:\", top_predictions)"
   ],
   "id": "d49a4edb86d34b19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Finally, what you've all been waiting for",
   "id": "98b38fe367de7e4e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Install the openai API\n",
    "```! pip install openai```"
   ],
   "id": "a53ee170ac4a8804"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load the API key",
   "id": "a760e66a8e86b507"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:43:55.262074Z",
     "start_time": "2024-12-09T14:43:55.257709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(dotenv_path=\"/Users/jacekdmochowski/.env\")  # Adjust the path if your .env file is elsewhere\n",
    "\n",
    "# Access the API key\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "id": "58b7032b11e33eb7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Talk to the GPT-4o model",
   "id": "c2f7750314de70e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:49:00.400017Z",
     "start_time": "2024-12-09T14:48:50.805757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert forecaster of the future.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What will 2025 bring to the world?\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ],
   "id": "3f2f3a83639c21d3",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T14:48:29.060936Z",
     "start_time": "2024-12-09T14:48:29.057124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = completion.choices[0].message.content\n",
    "# render with line breaks\n",
    "print(response.replace(\"\\n\", \"\\n\"))"
   ],
   "id": "321f06a18d452249",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the future with certainty is impossible, but based on current trends and data available up to October 2023, several developments and trends are likely to influence the world in 2025:\n",
      "\n",
      "1. **Technology and Artificial Intelligence**: AI will continue to advance, becoming more integrated into everyday life and business. We may see significant improvements in AI-driven healthcare, autonomous vehicles, and personalized education tools.\n",
      "\n",
      "2. **Climate Change and Environment**: Efforts to combat climate change will likely intensify. More countries may adopt aggressive policies to reduce carbon emissions, and renewable energy technologies, such as solar and wind, could see even wider adoption.\n",
      "\n",
      "3. **Global Economy**: The global economy will continue to adapt to challenges brought by technological changes and geopolitical tensions. Digital currencies and blockchain technology might gain more traction, impacting traditional financial systems.\n",
      "\n",
      "4. **Healthcare**: Advances in biotechnology and gene editing could lead to breakthroughs in treating diseases. The global focus on healthcare infrastructure might strengthen, influenced by lessons from the COVID-19 pandemic.\n",
      "\n",
      "5. **Geopolitical Landscape**: Geopolitical tensions could reshape alliances and economic partnerships. Issues such as cybersecurity, space exploration competition, and territorial disputes might be significant.\n",
      "\n",
      "6. **Social Change and Culture**: Social movements advocating for equality, diversity, and human rights are likely to grow stronger. The cultural landscape could continue to be shaped by digital media and communication platforms.\n",
      "\n",
      "7. **Urbanization and Infrastructure**: Smart cities and infrastructure projects utilizing IoT and AI could become more widespread, improving urban living conditions and efficiency.\n",
      "\n",
      "These predictions are speculative and can be influenced by unforeseen technological breakthroughs, natural events, and shifts in political climates.\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
