{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "392eae2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## BME i9400\n",
    "## Fall 2025\n",
    "### Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25280b31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "- In previous lectures, we covered vanilla neural networks: multilayer perceptrons\n",
    "- The building blocks of MLPs are *fully connected layers*\n",
    "- Before introducing convolutional networks, let's define a fully connected layer, as it will be used later in the lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea56d579",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fully connected layer\n",
    "- A fully connected layer is a layer in a neural network where each neuron is connected to every neuron in the previous layer\n",
    "- The output of a fully connected layer is computed as:\n",
    "---\n",
    "$y = \\sigma(Wx + b)$\n",
    "\n",
    "---\n",
    "where:\n",
    "- $y$ is the output of the layer (generally a vector)\n",
    "- $\\sigma$ is the activation function\n",
    "- $W$ is the weight matrix\n",
    "- $x$ is the input vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355bd171",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fully connected layer\n",
    "<img src=\"img/dense2.png\" alt=\"ANN Diagram\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d5457",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "- Convolutional Neural Networks (CNNs) are a class of neural networks that are particularly well-suited for processing data with *spatial* or *temporal* structure\n",
    "- Examples in biomedical engineering:\n",
    "    - Medical image analysis\n",
    "    - ECG/EEG signal processing\n",
    "    - Protein structure prediction\n",
    "    - Drug discovery\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70c4cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolution in 1-D\n",
    "- As the name suggests, the fundamental operation in CNNs is *convolution*\n",
    "- Convolution is a mathematical operation between two signals\n",
    "    - One of these signals may be viewed as the input, and the second as a filter\n",
    "    - NB: the \"filter\" is often referred to as a \"kernel\" in the context of CNNs\n",
    "    - Convolving the input with the filter produces an output signal (a third signal)\n",
    "- In 1-dimension, convolutions are often thought of as a temporal filtering operation:\n",
    "---\n",
    "$y(t) = (x * w)(t) = \\sum_{a=-\\infty}^{\\infty} x(a)w(t-a)$\n",
    "\n",
    "---\n",
    "where $x$ is the input signal, $w$ is the filter, and $y$ is the output signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb7731",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolution in 2-D\n",
    "- In 2 dimensions, the convolution operation is defined as:\n",
    "---\n",
    "$y(i,j) = (x * w)(i,j) = \\sum_m \\sum_n x(m,n)w(i-m,j-n)$\n",
    "\n",
    "---\n",
    "where $x$ is the 2-D input image (a 2-D image), $w$ is the 2-D filter, and $y$ is the output image.\n",
    "- Convolution in 2-D may be thought of as sliding the filter over the input image, and computing the dot product at each location\n",
    "- The output image is typically smaller than the input image\n",
    "- One example of a filter is the Sobel filter, which is used for edge detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803f88dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstrating convolution in 1-D\n",
    "- Without any further ado, let's demonstrate convolution in 1-D (super exciting, I know!)\n",
    "- Good news: ```numpy``` provides a function for convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc5164",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:46:15.719464Z",
     "start_time": "2024-11-11T20:46:15.223597Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1D Convolution Example\n",
    "def conv1d(signal, kernel):\n",
    "    return np.convolve(signal, kernel, mode='valid')\n",
    "\n",
    "# Create a sample signal and kernel\n",
    "t = np.linspace(0, 10, 1000)\n",
    "signal = np.sin(2*np.pi*t) + np.random.normal(0, 0.1, len(t))\n",
    "kernel = np.ones(50)/50  # Moving average filter\n",
    "\n",
    "# Apply convolution\n",
    "filtered_signal = conv1d(signal, kernel)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(t[:len(filtered_signal)], filtered_signal, label='Filtered')\n",
    "plt.plot(t[:len(filtered_signal)], signal[:len(filtered_signal)], alpha=0.5, label='Original')\n",
    "plt.title('1D Convolution Example')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e5c68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstrating 2-D convolutions\n",
    "- To demonstrate convolution in 2-D, we will use the ```scipy``` package to create a simple image and apply a 2-D convolution\n",
    "- We will use a simple edge detection kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d32174",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T20:52:07.670387Z",
     "start_time": "2024-11-11T20:52:06.541791Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "# Create a sample image\n",
    "image = np.zeros((10, 10))\n",
    "image[4:7, 4:7] = 1\n",
    "\n",
    "# Create an edge detection kernel\n",
    "kernel = np.array([[-1, -1, -1],\n",
    "                  [-1,  8, -1],\n",
    "                  [-1, -1, -1]])\n",
    "\n",
    "# Apply 2D convolution\n",
    "conv_result = signal.convolve2d(image, kernel, mode='valid')\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ax1.imshow(image, cmap='hot', vmin=-1, vmax=1)\n",
    "ax1.set_title('Original Image')\n",
    "plt.colorbar(ax1.imshow(image, cmap='hot', vmin=-1, vmax=1), ax=ax1)\n",
    "ax2.imshow(conv_result, cmap='hot', vmin=-1, vmax=1)\n",
    "ax2.set_title('After Convolution')\n",
    "plt.colorbar(ax2.imshow(conv_result, cmap='hot', vmin=-1, vmax=1), ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab5a67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Use Convolutions in Neural Networks?\n",
    "1. Weight Sharing\n",
    "   - Same kernel is applied across the entire input\n",
    "   - Reduces number of parameters\n",
    "   - Translation invariance\n",
    "\n",
    "2. Local Features\n",
    "   - Each output value depends only on nearby input values\n",
    "   - Captures spatial relationships\n",
    "   - Hierarchical feature learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77625b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1D Convolutional Layers\n",
    "- Used for processing *sequential* data\n",
    "- The filter slides across the input, computing an output at each location (see below)\n",
    "- Examples in biomedical engineering:\n",
    "    - ECG signals\n",
    "    - EEG recordings\n",
    "    - Blood pressure time series\n",
    "\n",
    "## 1D Convolutional Layer\n",
    "<img src=\"img/conv1d.jpeg\" alt=\"1D Convolution\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4661000",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2D Convolutional Layers\n",
    "- Used for processing image data\n",
    "- The filter slides across the input image (moves left to right, as well as top to bottom), computing an output at each location\n",
    "- Examples in biomedical engineering:\n",
    "    - X-ray images\n",
    "    - MRI scans\n",
    "    - Histology slides\n",
    "    - Microscopy images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864c45b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2D Convolutional Layer\n",
    "<img src=\"img/conv2d.jpeg\" alt=\"2D Convolution\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baba3ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pooling Layers\n",
    "- Convolutions are almost always paired with *pooling*\n",
    "    - Pooling means that we reduce the value of a region of the input to a single value\n",
    "- Types:\n",
    "    - Max pooling (most common): take the maximum value in the region\n",
    "    - Average pooling: take the average value in the region\n",
    "- Benefits:\n",
    "    - Reduces computation\n",
    "    - Provides some translation invariance\n",
    "    - Helps prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd46914",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Max pooling example\n",
    "<img src=\"img/pooling.jpeg\" alt=\"Max Pooling\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e101443f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Striding\n",
    "- Controls how the kernel moves across the input\n",
    "- A stride of 1 means that the kernel moves one pixel at a time\n",
    "- Larger stride = reduced output size\n",
    "- Can be used instead of or in addition to pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a2113",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Striding\n",
    "<img src=\"img/strides.jpeg\" alt=\"Striding\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a90d59b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applications of CNNs in Biomedical Engineering\n",
    "1. 1D CNNs:\n",
    "   - ECG classification\n",
    "   - Sleep stage scoring\n",
    "   - Seizure detection\n",
    "\n",
    "2. 2D CNNs:\n",
    "   - Medical image segmentation\n",
    "   - Disease classification\n",
    "   - Cell detection\n",
    "\n",
    "3. 3D CNNs:\n",
    "   - Volumetric medical imaging (CT, MRI)\n",
    "   - Drug-protein interaction prediction\n",
    "   - Motion analysis in medical videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b405b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstrating 2-D CNNs in PyTorch\n",
    "- Let's create a simple CNN model in PyTorch\n",
    "- We will work with the popular MNIST dataset of handwritten digits\n",
    "- The goal of the model is to classify the digits into one of 10 classes (0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ebf1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:23:13.256524Z",
     "start_time": "2024-11-11T21:23:11.625385Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # 1 input \"channel\", 10 output channels, 5x5 kernel\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # 10 input channels, 20 output channels, 5x5 kernel\n",
    "        self.pool = nn.MaxPool2d(2) # 2x2 max pooling\n",
    "        self.fc = nn.Linear(320, 10) # Fully connected layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 320)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367f26a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the MNIST dataset in Python\n",
    "- We will use the ```torchvision``` package to load the MNIST dataset\n",
    "- The dataset consists of 60,000 training images and 10,000 test images\n",
    "- Each image is a 28x28 pixel grayscale image\n",
    "- The images are labeled with the corresponding digit (0-9)\n",
    "- We will use a batch size of 64 for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104680d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:23:18.891832Z",
     "start_time": "2024-11-11T21:23:18.839834Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f880d756cc3b02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T21:24:32.226613Z",
     "start_time": "2024-11-11T21:24:32.151885Z"
    }
   },
   "outputs": [],
   "source": [
    "# display a sample image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_dataset[1][0].squeeze(), cmap='gray')\n",
    "plt.title(f'Label: {train_dataset[1][1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4d71db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Instantiate the model, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac1c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:38:57.719265Z",
     "start_time": "2024-11-06T19:38:57.698304Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b701326",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining a training function\n",
    "- To make the code modular, let's define a function for training the model\n",
    "- The function will take the following arguments:\n",
    "    - The model object\n",
    "    - The training dataloader object\n",
    "    - The optimizer object\n",
    "    - The epoch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b54cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:41:34.967880Z",
     "start_time": "2024-11-06T19:41:34.960759Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1333518",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining a test function\n",
    "- Similarily, let's define a function for testing the model\n",
    "- Instead of performing gradient descent and updating the model parameters, this function will be tasked with making predictions on the test set and measuring the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc8af40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:43:05.229140Z",
     "start_time": "2024-11-06T19:43:05.222780Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, '\n",
    "          f'Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({100. * correct / len(test_loader.dataset):.2f}%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc726b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training and evaluating the model\n",
    "- In the following code block, we will train the model for 3 epochs\n",
    "- At the end of each epoch, we will evaluate the model on the test set and report the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f6df4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T19:43:58.272753Z",
     "start_time": "2024-11-06T19:43:29.459598Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model for 3 epochs\n",
    "for epoch in range(1, 4):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "bmei9400b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
